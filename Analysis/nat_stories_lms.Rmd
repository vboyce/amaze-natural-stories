---
title: "Natural Stories LM analysis"
output: github_document
---
```{r, include=F}
knitr::opts_chunk$set(echo = FALSE, warning=F)
options(knitr.table.format = "html")
library(tidyverse)
library(readr)
library(brms)
library(lme4)
library(rstan)
library(tidybayes)
library(knitr)
library(matrixStats)
theme_set(theme_bw())
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
```

```{r participants}

data <- read_rds("../Data/cleaned.rds")

data_filt <- data %>% filter(native %in% c("ENG", "English", "ENGLISH", "english")) #I peeked at what people put that semantically maps to english

data_error_summ <- data_filt %>% 
  mutate(correct.num=ifelse(correct=="yes", 1,0)) %>% 
  group_by(subject) %>%
  filter(type!="practice") %>% 
  filter(rt<5000) %>% 
  summarize(pct_correct=mean(correct.num)) %>% 
  ungroup() %>% 
  mutate(is.attentive=ifelse(pct_correct>.8, T,F)) %>% 
  select(subject, is.attentive)

data_low_error <- data_filt %>% 
  left_join(data_error_summ, by="subject") %>% 
  filter(is.attentive) %>% 
  filter(type!="practice")

  data_error_free <- data_low_error %>% 
    mutate(word_num_mistake=ifelse(correct=="no", word_num,NA)) %>% 
    group_by(sentence, subject) %>% fill(word_num_mistake) %>% ungroup() %>% 
    mutate(after_mistake=word_num-word_num_mistake,
           after_mistake=ifelse(is.na(after_mistake),0,after_mistake)) %>% 
    filter(correct=="yes") %>% 
    filter(!after_mistake %in% c(1,2))
  
data_no_first <- data_error_free %>% filter(word_num!=0)

data_ready <- data_no_first %>% filter(rt>100 & rt<5000) %>% 
  select(subject, word_num, word, rt, sentence, type)

data_post_only <- data_no_first %>% filter(rt>100 & rt<5000) %>% 
  filter(!after_mistake==0) %>% 
    select(subject, word_num, word, rt, sentence, type)

data_pre_error <- data_no_first %>% filter(rt>100 & rt<5000) %>% 
  filter(after_mistake==0) %>% 
  select(subject, word_num, word, rt, sentence, type)

data_stories <- data_ready %>% select(type, subject) %>% 
  unique() %>% 
  group_by(type) %>% 
  tally()
```


# Overview

`r data %>% select(subject) %>% unique() %>% nrow()` participants read naturalistic stories from the natural stories corpus. Each participant read 1 story. 

We exclude

- participants who do not report English as a native language (`r data_filt %>% select(subject) %>% unique() %>% nrow()` remaining)
- participants who do not get 80% of the words correct (`r data_low_error %>% select(subject) %>% unique() %>% nrow()` remaining)
- practice items (`r data_low_error %>% nrow()` words remaining)
- words that were wrong or were within two after a mistake (`r data_error_free %>% nrow()` words remaining)
- the first word of every sentence (didn't have a real distractor, RT is measured slightly differently) (`r data_no_first %>% nrow()` words remaining)
- words with RTs <100 or >5000 (<100 we think is likely a recording error, or at least not reading the words at all, >5000 is likely getting distracted) (`r data_ready %>% nrow()` words remaining)

Within the filtered data, each story was read between `r min(data_stories$n)` and `r max(data_stories$n)` times, for an average of `r mean(data_stories$n)`.

We also do the analyses on only the words before mistakes (per sentence) (`r data_pre_error %>% nrow()` words)

From the modelling side:
(After attempts without doing this filtering) we only include words which are single token and known words in each of the models vocabularies. We also only include words with frequencies. This is roughly equivalent to excluding words with punctuation. 

We use as predictors:

- length in characters of stripped word
- unigram frequency of word. Frequencies for words are calculated using word_tokenize on the gulordava train data and counting up instances. (This tends to tokenize off punctuation, but is capitalization sensitive). Frequencies are represented as log2 of the expected occurances in 1 billion words. 

Surprisals are measured in bits.

- ngram (5-gram KN smoothed)
- GRNN
- Transformer-XL

We center the predictors for the brms models, but don't rescale them. 

The model formula we use is rt ~ surp* length +  freq * length + past_surp * past_length + past_freq * past_length.

```{r labels}
labs <- read_rds("../Prep_code/natural_stories_surprisals.rds") %>% left_join(read_delim("../Materials/natural_stories_sentences.tsv", delim="\t")) %>% 
  select(word_num=Word_In_Sentence_Num, word=Word, sentence=Sentence, everything())

select_labs <- labs %>% 
  filter(ngram_token_count==1 & txl_token_count==1 & grnn_token_count==1) %>% 
  filter(!is.na(txl_surp) & !is.na(ngram_surp) & !is.na(grnn_surp) & !is.na(freq) & !is.na(length)) %>% 
    mutate(txl_center=txl_surp-mean(txl_surp, na.rm=T),
         ngram_center=ngram_surp-mean(ngram_surp, na.rm=T),
         grnn_center=grnn_surp-mean(grnn_surp, na.rm=T),
         freq_center=freq-mean(freq, na.rm=T),
         length_center=length-mean(length, na.rm=T))

past_word <- select_labs %>% 
  mutate(word_num=word_num+1) %>% 
  rename(past_txl=txl_surp, past_ngram=ngram_surp, past_grnn=grnn_surp, past_freq=freq, past_length=length,past_c_txl=txl_center, past_c_ngram=ngram_center, past_c_grnn=grnn_center, past_c_freq=freq_center, past_c_length=length_center) %>% 
  select(sentence,Story_Num,Sentence_Num, word_num, starts_with("past")) %>% 
  left_join(select_labs, by=c("Story_Num","Sentence_Num","sentence", "word_num"))



labelled_pre_error <- data_pre_error %>% inner_join(past_word, by=c("word_num", "word", "sentence")) %>%
  filter(word_num>1) %>% 
  select(rt, subject, Word_In_Story_Num, word, Story_Num,txl_surp,ngram_surp,grnn_surp, freq,length,
         txl_center, ngram_center,grnn_center,freq_center, length_center, starts_with("past")) %>% 
  mutate(Word_ID=as_factor(str_c(Story_Num, Word_In_Story_Num, sep="_"))) %>% 
  select(-Word_In_Story_Num, -Story_Num) %>% write_rds("pre_error.rds")

labelled_post_error <- data_ready %>% inner_join(past_word, by=c("word_num", "word", "sentence")) %>%
  filter(word_num>1) %>% 
select(rt, subject, Word_In_Story_Num, Story_Num,txl_surp,ngram_surp,grnn_surp, freq,length,
         txl_center, ngram_center,grnn_center,freq_center, length_center, starts_with("past")) %>% 
  mutate(Word_ID=as_factor(str_c(Story_Num, Word_In_Story_Num, sep="_"))) %>% 
  select(-Word_In_Story_Num, -Story_Num) %>% write_rds("post_error.rds")

labelled_post_only <- data_post_only %>% inner_join(past_word, by=c("word_num", "word", "sentence")) %>%
  filter(word_num>1) %>% 
select(rt, subject, Word_In_Story_Num, Story_Num,txl_surp,ngram_surp,grnn_surp, freq,length,
         txl_center, ngram_center,grnn_center,freq_center, length_center, starts_with("past")) %>% 
  mutate(Word_ID=as_factor(str_c(Story_Num, Word_In_Story_Num, sep="_"))) %>% 
  select(-Word_In_Story_Num, -Story_Num)
```

```{r}

lab_summary <- select_labs %>% summarize_at(c("length","freq","txl_surp","grnn_surp","ngram_surp"), list(mean=mean, stdev=sd, min=min, max=max)) %>% 
  pivot_longer(everything()) %>% arrange(name)

lab_summary
```


## BRM models

We include a by-subject effect for everything, and a by_word random intercept (full mixed effects). 

Priors:

- normal(1000,1000) for intercept -- we think RTs are about 1 second usually
- normal(0,500) for beta and sd -- we don't really know what effects are
- lkj(1) for correlations -- we don't have reason to think correlations might go any particular way 

```{r}
  priors <- c(
      set_prior("normal(1000, 1000)", class="Intercept"),
      set_prior("normal(0, 500)", class="b"),
      set_prior("normal(0, 500)", class="sd"),
      set_prior("lkj(1)",       class="cor"))
  

```

### On pre-error data only 
```{r}
brm_ngram_interact <- brm(rt ~ ngram_center* length_center + freq_center * length_center + 
                         past_c_ngram*past_c_length + past_c_freq*past_c_length + 
                         (ngram_center* length_center + freq_center * length_center + 
                            past_c_ngram *past_c_length+ past_c_freq*past_c_length|subject)+
                         (1|Word_ID), data=labelled_pre_error, 
                       file="brm_ngram_interact", prior=priors, control=list(adapt_delta=.95))

brm_grnn_interact <- brm(rt ~ grnn_center * length_center+ freq_center * length_center + 
                         past_c_grnn *past_c_length+ past_c_freq*past_c_length + 
                         (grnn_center* length_center + freq_center * length_center + 
                            past_c_grnn*past_c_length + past_c_freq*past_c_length|subject)+
                        (1|Word_ID), data=labelled_pre_error, 
                       file="brm_grnn_interact", prior=priors, control=list(adapt_delta=.95))

brm_txl_interact <- brm(rt ~ txl_center* length_center + freq_center * length_center + 
                         past_c_txl*past_c_length + past_c_freq*past_c_length + 
                         (txl_center* length_center + freq_center * length_center + 
                            past_c_txl *past_c_length+ past_c_freq*past_c_length|subject)+
                       (1|Word_ID), data=labelled_pre_error, 
                       file="brm_txl_interact", prior=priors, control=list(adapt_delta=.95))

```


```{r}

show_summary <- function(model){
  intervals <- gather_draws(model, `b_.*`, regex=T) %>% mean_qi()
  
  stats <- gather_draws(model, `b_.*`, regex=T) %>% 
    mutate(above_0=ifelse(.value>0, 1,0)) %>% 
    group_by(.variable) %>% 
    summarize(pct_above_0=mean(above_0)) %>% 
    mutate(`P` = signif(2*pmin(pct_above_0,1-pct_above_0), digits=2)) %>% 
    left_join(intervals, by=".variable") %>% 
    mutate(lower=round(.lower, digits=1),
           upper=round(.upper, digits=1),
           E=round(.value, digits=1),
           `CI`=str_c("[",lower,", ", upper,"]"),
           Term=str_sub(.variable, 3, -1),
           ) %>% 
    select(Term, `E`, `CI`,`P`)
  
  stats
}
a <- show_summary(brm_txl_interact) %>% mutate(model="TXL") %>% mutate(Term=str_replace(Term,"txl","surp"))
b <- show_summary(brm_grnn_interact) %>% mutate(model="GRNN") %>% mutate(Term=str_replace(Term,"grnn","surp"))
c <- show_summary(brm_ngram_interact) %>% mutate(model="5-gram") %>% mutate(Term=str_replace(Term,"ngram","surp"))

summ <- a %>% union(b) %>% union(c) %>% pivot_wider(names_from="model", values_from=c(`E`,`CI`,`P`)) %>% 
  select(Term, `E_5-gram`, `CI_5-gram`, `P_5-gram`, `E_GRNN`, CI_GRNN, P_GRNN, E_TXL, CI_TXL, P_TXL)

library(xtable)
print(xtable(summ,digits=c(0,0,1,0,2,1,0,2,1,0,2)), include.rownames=FALSE)
```

### On post-error as well

```{r}
brm_ngram_interact_post <- brm(rt ~ ngram_center* length_center + freq_center * length_center + 
                         past_c_ngram*past_c_length + past_c_freq*past_c_length + 
                         (ngram_center* length_center + freq_center * length_center + 
                            past_c_ngram *past_c_length+ past_c_freq*past_c_length|subject)+
                         (1|Word_ID), data=labelled_post_error, 
                       file="brm_ngram_interact_post", prior=priors, control=list(adapt_delta=.95))

brm_grnn_interact_post <- brm(rt ~ grnn_center * length_center+ freq_center * length_center + 
                         past_c_grnn *past_c_length+ past_c_freq*past_c_length + 
                         (grnn_center* length_center + freq_center * length_center + 
                            past_c_grnn*past_c_length + past_c_freq*past_c_length|subject)+
                        (1|Word_ID), data=labelled_post_error, 
                       file="brm_grnn_interact_post", prior=priors, control=list(adapt_delta=.95))

brm_txl_interact_post <- brm(rt ~ txl_center* length_center + freq_center * length_center + 
                         past_c_txl*past_c_length + past_c_freq*past_c_length + 
                         (txl_center* length_center + freq_center * length_center + 
                            past_c_txl *past_c_length+ past_c_freq*past_c_length|subject)+
                       (1|Word_ID), data=labelled_post_error, 
                       file="brm_txl_interact_post", prior=priors, control=list(adapt_delta=.95))

```
```{r}
show_summary_2 <- function(model){
  intervals <- gather_draws(model, `b_.*`, regex=T) %>% mean_qi()
  
  stats <- gather_draws(model, `b_.*`, regex=T) %>% 
    mutate(above_0=ifelse(.value>0, 1,0)) %>% 
    group_by(.variable) %>% 
    summarize(pct_above_0=mean(above_0)) %>% 
    mutate(`P-value equivalent` = signif(2*pmin(pct_above_0,1-pct_above_0), digits=2)) %>% 
    left_join(intervals, by=".variable") %>% 
    mutate(lower=round(.lower, digits=2),
           upper=round(.upper, digits=2),
           `Credible Interval`=str_c("[",lower,", ", upper,"]"),
           Term=str_sub(.variable, 3, -1),
           Estimate=round(.value, digits=2)) %>% 
    select(Term, Estimate, `Credible Interval`, `P-value equivalent`)
  
  stats
}
```

### Summaries

```{r}
# summary(brm_ngram_interact_post)
# summary(brm_ngram_interact)
# 
# summary(brm_grnn_interact_post)
# summary(brm_grnn_interact)
# 
# summary(brm_txl_interact_post)
# summary(brm_txl_interact)
```

## Log likelihoods

```{r}


#given a vector of logs, find harmonic mean
#uses one of the formulae from wikipedia page so we have underflow and not overflow issues
#then use logSumExp to reduce underflow
get_harmonic <- function(d){
  l <- length(d)
  log_prod <- sum(d) #this is the log of the product 
  log_inv <- d*-1 # this is list of logs of inverses
  log_inv_prod <- log_inv+log_prod #we "multiply" by the product, all of these are now teeny
  log_sum <- logSumExp(log_inv_prod) #we sum these up, still logged
  overall <- l * exp(log_prod-log_sum)
  
  overall
}

 # a <- log_lik(brm_ngram_interact)
 # 
 # b <- log_lik(brm_grnn_interact)
 # 
 # c <- log_lik(brm_txl_interact)
 # 
 # get_harmonic(a)
 # 
 # get_harmonic(b)    
 # 
 # get_harmonic(c)
```

I get 9.087e-32 for Ngram, 3.602e-32 for GRNN, and 2.24e-33 for TXL. I'm not sure this is the order we expect, and not sure how to interpret it. (Also not sure I did things right.)

# Frequentist LMs

```{r}
#mean by subject for each word
d_lm <- labelled_pre_error %>% group_by(word, txl_center, ngram_center, grnn_center, freq_center, length_center,
                                        past_c_txl, past_c_ngram, past_c_grnn, past_c_freq, past_c_length, Word_ID) %>% 
  summarize(mean_rt=mean(rt))
```

## Models

We want to be able to do nested model comparision, so we want models with 
- only length, frequency fx
- each 1 surprisal model as predictor
- all the surprisals

For now, no interactions between surprisal and others, and if we include a predictor, include both current and lagged of it. 

```{r}

no_surp <- lmer(mean_rt ~ freq_center*length_center+past_c_freq*past_c_length+(1|word), data=d_lm)

ngram_only <- lmer(mean_rt ~ ngram_center + past_c_ngram + freq_center*length_center+past_c_freq*past_c_length+(1|word), data=d_lm)

grnn_only <- lmer(mean_rt ~ grnn_center + past_c_grnn + freq_center*length_center+past_c_freq*past_c_length+(1|word), data=d_lm)

txl_only <- lmer(mean_rt ~ txl_center + past_c_txl + freq_center*length_center+past_c_freq*past_c_length+(1|word), data=d_lm)

all_surp <- lmer(mean_rt ~ ngram_center + past_c_ngram + 
                   grnn_center + past_c_grnn +
                   txl_center + past_c_txl +
                   freq_center*length_center+past_c_freq*past_c_length+(1|word), data=d_lm)


ngram_grnn <-  lmer(mean_rt ~ ngram_center + past_c_ngram + 
                   grnn_center + past_c_grnn +
                   freq_center*length_center+past_c_freq*past_c_length+(1|word), data=d_lm)

ngram_txl <-  lmer(mean_rt ~ ngram_center + past_c_ngram + 
                   txl_center + past_c_txl +
                   freq_center*length_center+past_c_freq*past_c_length+(1|word), data=d_lm)

grnn_txl <-  lmer(mean_rt ~ grnn_center + past_c_grnn +
                   txl_center + past_c_txl +
                   freq_center*length_center+past_c_freq*past_c_length+(1|word), data=d_lm)

no_lag <-  lmer(mean_rt ~ ngram_center +
                   grnn_center +
                   txl_center + 
                   freq_center*length_center+(1|word), data=d_lm)

no_surp_lag <-  lmer(mean_rt ~ ngram_center +  
                   grnn_center + 
                   txl_center +                    freq_center*length_center+past_c_freq*past_c_length+(1|word), data=d_lm)

  only_surp_lag <-  lmer(mean_rt ~ ngram_center + past_c_ngram + 
                   grnn_center + past_c_grnn +
                   txl_center + past_c_txl +
                   freq_center*length_center+(1|word), data=d_lm)
```

```{r}

anova(all_surp, txl_only)
anova(all_surp, grnn_only)
anova(all_surp, ngram_only)

anova(txl_only, no_surp)
anova(grnn_only, no_surp)
anova(ngram_only, no_surp)

anova(all_surp, ngram_grnn)
anova(all_surp, ngram_txl)
anova(all_surp, grnn_txl)

anova(ngram_grnn, ngram_only)
anova(ngram_grnn, grnn_only)
anova(ngram_txl, ngram_only)
anova(ngram_txl, txl_only)
anova(grnn_txl, grnn_only)
anova(grnn_txl, txl_only)

anova(all_surp, no_lag)

anova(all_surp, no_surp_lag)

anova(no_surp_lag, no_lag) 

anova(all_surp, only_surp_lag)

anova(only_surp_lag, no_lag)
```
In general, adding to the model makes it better. 

The model with all 3 surprisal predictors is better than any model with only one. Any one surprisal predictor is better than no surprisals predictors. 

However, adding ngram predictors to a model that already has txl & grnn does not help. 
In other cases, adding the 3rd surprisal source to the other two does help. 

Ngram+Grnn is not better than Grnn only. Otherwise, pairs are better than singletons. This suggests that Ngram's info is a subset of GRNN, but not a subset of TXL. 

Past surprisal predictors don't help (with or without past freq,length effects in the models), but past freq,length do (with or without past surprisal predictors). 



